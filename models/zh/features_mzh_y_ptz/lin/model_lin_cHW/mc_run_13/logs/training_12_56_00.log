2022-03-03 12:56:00,274:INFO:All directories created, ready to load the data
2022-03-03 12:56:00,316:INFO:Dataset loaded from /data/theorie/jthoeve/training_data/zh/features_mzh_y_ptz_v2/lin/cHW/events_13.pkl.gz
2022-03-03 12:56:00,347:INFO:Dataset loaded from /data/theorie/jthoeve/training_data/zh/features_mzh_y_ptz_v2/sm/events_13.pkl.gz
2022-03-03 12:56:02,717:INFO:Epoch 1, Training loss 208003.203125, Validation loss 208003.203125
2022-03-03 12:56:05,096:INFO:Epoch 2, Training loss 208003.203125, Validation loss 208003.203125
2022-03-03 12:56:07,615:INFO:Epoch 3, Training loss 208003.203125, Validation loss 208003.203125
2022-03-03 12:56:10,121:INFO:Epoch 4, Training loss 208003.203125, Validation loss 208003.203125
2022-03-03 12:56:12,556:INFO:Epoch 5, Training loss 208003.203125, Validation loss 208003.203125
2022-03-03 12:56:15,003:INFO:Epoch 6, Training loss 208003.203125, Validation loss 208003.203125
2022-03-03 12:56:17,528:INFO:Epoch 7, Training loss 208003.203125, Validation loss 208003.203125
2022-03-03 12:56:19,916:INFO:Epoch 8, Training loss 208003.203125, Validation loss 208003.203125
2022-03-03 12:56:22,318:INFO:Epoch 9, Training loss 208003.203125, Validation loss 208003.203125
2022-03-03 12:56:24,797:INFO:Epoch 10, Training loss 208003.203125, Validation loss 208003.203125
2022-03-03 12:56:27,191:INFO:Epoch 11, Training loss 208003.203125, Validation loss 208003.203125
2022-03-03 12:56:27,195:INFO:Detected stagant training, reset the weights
2022-03-03 12:56:29,571:INFO:Epoch 12, Training loss 146552.96484375, Validation loss 136292.71484375
2022-03-03 12:56:32,080:INFO:Epoch 13, Training loss 130564.724609375, Validation loss 123223.126953125
2022-03-03 12:56:34,605:INFO:Epoch 14, Training loss 119746.126953125, Validation loss 115500.2734375
2022-03-03 12:56:37,011:INFO:Epoch 15, Training loss 113624.416015625, Validation loss 111469.76171875
2022-03-03 12:56:39,391:INFO:Epoch 16, Training loss 110625.630859375, Validation loss 109859.462890625
2022-03-03 12:56:41,807:INFO:Epoch 17, Training loss 109688.94921875, Validation loss 109717.80859375
2022-03-03 12:56:44,311:INFO:Epoch 18, Training loss 109719.666015625, Validation loss 109796.814453125
2022-03-03 12:56:46,777:INFO:Epoch 19, Training loss 109687.876953125, Validation loss 109606.369140625
2022-03-03 12:56:49,242:INFO:Epoch 20, Training loss 109460.927734375, Validation loss 109387.197265625
2022-03-03 12:56:51,677:INFO:Epoch 21, Training loss 109290.70703125, Validation loss 109290.91796875
2022-03-03 12:56:54,278:INFO:Epoch 22, Training loss 109227.68359375, Validation loss 109253.98828125
2022-03-03 12:56:56,724:INFO:Epoch 23, Training loss 109182.23828125, Validation loss 109194.669921875
2022-03-03 12:56:59,109:INFO:Epoch 24, Training loss 109117.2265625, Validation loss 109140.583984375
2022-03-03 12:57:01,713:INFO:Epoch 25, Training loss 109070.18359375, Validation loss 109109.767578125
2022-03-03 12:57:04,097:INFO:Epoch 26, Training loss 109029.0859375, Validation loss 109066.39453125
2022-03-03 12:57:06,644:INFO:Epoch 27, Training loss 108978.978515625, Validation loss 109024.01171875
2022-03-03 12:57:09,227:INFO:Epoch 28, Training loss 108931.705078125, Validation loss 108979.6796875
2022-03-03 12:57:11,656:INFO:Epoch 29, Training loss 108881.4921875, Validation loss 108933.27734375
2022-03-03 12:57:14,070:INFO:Epoch 30, Training loss 108829.4765625, Validation loss 108883.90234375
2022-03-03 12:57:16,487:INFO:Epoch 31, Training loss 108775.474609375, Validation loss 108833.921875
2022-03-03 12:57:18,948:INFO:Epoch 32, Training loss 108720.794921875, Validation loss 108784.330078125
2022-03-03 12:57:21,390:INFO:Epoch 33, Training loss 108666.01171875, Validation loss 108736.8671875
2022-03-03 12:57:23,890:INFO:Epoch 34, Training loss 108614.521484375, Validation loss 108693.59375
2022-03-03 12:57:26,308:INFO:Epoch 35, Training loss 108566.732421875, Validation loss 108659.736328125
2022-03-03 12:57:28,720:INFO:Epoch 36, Training loss 108530.83203125, Validation loss 108640.05078125
2022-03-03 12:57:31,083:INFO:Epoch 37, Training loss 108506.892578125, Validation loss 108633.51953125
2022-03-03 12:57:33,501:INFO:Epoch 38, Training loss 108495.59375, Validation loss 108630.240234375
2022-03-03 12:57:35,854:INFO:Epoch 39, Training loss 108485.15234375, Validation loss 108621.236328125
2022-03-03 12:57:38,304:INFO:Epoch 40, Training loss 108477.31640625, Validation loss 108616.798828125
2022-03-03 12:57:40,748:INFO:Epoch 41, Training loss 108472.421875, Validation loss 108615.826171875
2022-03-03 12:57:43,153:INFO:Epoch 42, Training loss 108469.421875, Validation loss 108616.21875
2022-03-03 12:57:45,751:INFO:Epoch 43, Training loss 108466.091796875, Validation loss 108612.083984375
2022-03-03 12:57:48,216:INFO:Epoch 44, Training loss 108462.724609375, Validation loss 108612.81640625
2022-03-03 12:57:50,626:INFO:Epoch 45, Training loss 108461.005859375, Validation loss 108614.20703125
2022-03-03 12:57:53,241:INFO:Epoch 46, Training loss 108457.017578125, Validation loss 108606.978515625
2022-03-03 12:57:55,669:INFO:Epoch 47, Training loss 108454.9375, Validation loss 108607.599609375
2022-03-03 12:57:58,094:INFO:Epoch 48, Training loss 108454.201171875, Validation loss 108608.00390625
2022-03-03 12:58:00,536:INFO:Epoch 49, Training loss 108451.16796875, Validation loss 108611.25390625
2022-03-03 12:58:02,976:INFO:Epoch 50, Training loss 108448.4765625, Validation loss 108608.20703125
2022-03-03 12:58:05,488:INFO:Epoch 51, Training loss 108446.830078125, Validation loss 108606.91796875
2022-03-03 12:58:07,933:INFO:Epoch 52, Training loss 108446.58984375, Validation loss 108606.27734375
2022-03-03 12:58:10,394:INFO:Epoch 53, Training loss 108443.841796875, Validation loss 108606.9140625
2022-03-03 12:58:12,835:INFO:Epoch 54, Training loss 108443.09765625, Validation loss 108605.533203125
2022-03-03 12:58:15,290:INFO:Epoch 55, Training loss 108441.458984375, Validation loss 108609.80078125
2022-03-03 12:58:17,726:INFO:Epoch 56, Training loss 108441.08984375, Validation loss 108609.19140625
2022-03-03 12:58:20,367:INFO:Epoch 57, Training loss 108440.66015625, Validation loss 108605.765625
2022-03-03 12:58:22,758:INFO:Epoch 58, Training loss 108437.693359375, Validation loss 108605.091796875
2022-03-03 12:58:25,387:INFO:Epoch 59, Training loss 108437.80078125, Validation loss 108607.548828125
2022-03-03 12:58:27,863:INFO:Epoch 60, Training loss 108438.080078125, Validation loss 108608.423828125
2022-03-03 12:58:30,314:INFO:Epoch 61, Training loss 108440.044921875, Validation loss 108606.419921875
2022-03-03 12:58:32,759:INFO:Epoch 62, Training loss 108438.07421875, Validation loss 108605.416015625
2022-03-03 12:58:35,245:INFO:Epoch 63, Training loss 108438.869140625, Validation loss 108611.736328125
2022-03-03 12:58:37,736:INFO:Epoch 64, Training loss 108439.087890625, Validation loss 108608.98828125
2022-03-03 12:58:40,270:INFO:Epoch 65, Training loss 108433.8671875, Validation loss 108601.5234375
2022-03-03 12:58:42,779:INFO:Epoch 66, Training loss 108433.638671875, Validation loss 108603.73046875
2022-03-03 12:58:45,299:INFO:Epoch 67, Training loss 108432.4296875, Validation loss 108610.69140625
2022-03-03 12:58:47,727:INFO:Epoch 68, Training loss 108432.123046875, Validation loss 108606.564453125
2022-03-03 12:58:50,164:INFO:Epoch 69, Training loss 108430.4453125, Validation loss 108600.9140625
2022-03-03 12:58:52,622:INFO:Epoch 70, Training loss 108432.490234375, Validation loss 108603.7109375
2022-03-03 12:58:55,123:INFO:Epoch 71, Training loss 108430.2265625, Validation loss 108610.5
2022-03-03 12:58:57,567:INFO:Epoch 72, Training loss 108431.68359375, Validation loss 108606.2890625
2022-03-03 12:59:00,012:INFO:Epoch 73, Training loss 108428.298828125, Validation loss 108602.123046875
2022-03-03 12:59:02,479:INFO:Epoch 74, Training loss 108428.8125, Validation loss 108607.728515625
2022-03-03 12:59:04,852:INFO:Epoch 75, Training loss 108428.615234375, Validation loss 108601.890625
2022-03-03 12:59:07,369:INFO:Epoch 76, Training loss 108427.400390625, Validation loss 108605.486328125
2022-03-03 12:59:09,848:INFO:Epoch 77, Training loss 108426.16796875, Validation loss 108606.59765625
2022-03-03 12:59:12,269:INFO:Epoch 78, Training loss 108425.734375, Validation loss 108604.9609375
2022-03-03 12:59:14,625:INFO:Epoch 79, Training loss 108425.375, Validation loss 108603.205078125
2022-03-03 12:59:17,060:INFO:Epoch 80, Training loss 108425.359375, Validation loss 108605.560546875
2022-03-03 12:59:19,458:INFO:Epoch 81, Training loss 108424.791015625, Validation loss 108606.828125
2022-03-03 12:59:21,939:INFO:Epoch 82, Training loss 108424.603515625, Validation loss 108602.791015625
2022-03-03 12:59:24,358:INFO:Epoch 83, Training loss 108426.251953125, Validation loss 108604.87890625
2022-03-03 12:59:26,856:INFO:Epoch 84, Training loss 108424.689453125, Validation loss 108606.40625
2022-03-03 12:59:29,224:INFO:Epoch 85, Training loss 108423.6640625, Validation loss 108609.34765625
2022-03-03 12:59:31,758:INFO:Epoch 86, Training loss 108427.796875, Validation loss 108602.087890625
2022-03-03 12:59:34,156:INFO:Epoch 87, Training loss 108422.56640625, Validation loss 108608.814453125
2022-03-03 12:59:36,619:INFO:Epoch 88, Training loss 108422.44140625, Validation loss 108604.4921875
2022-03-03 12:59:38,998:INFO:Epoch 89, Training loss 108421.513671875, Validation loss 108605.853515625
2022-03-03 12:59:41,482:INFO:Epoch 90, Training loss 108421.51953125, Validation loss 108604.263671875
2022-03-03 12:59:44,027:INFO:Epoch 91, Training loss 108421.880859375, Validation loss 108607.775390625
2022-03-03 12:59:46,436:INFO:Epoch 92, Training loss 108421.291015625, Validation loss 108604.1953125
2022-03-03 12:59:48,993:INFO:Epoch 93, Training loss 108423.0703125, Validation loss 108608.615234375
2022-03-03 12:59:51,490:INFO:Epoch 94, Training loss 108420.84765625, Validation loss 108604.763671875
2022-03-03 12:59:53,953:INFO:Epoch 95, Training loss 108420.47265625, Validation loss 108604.416015625
2022-03-03 12:59:56,311:INFO:Epoch 96, Training loss 108420.685546875, Validation loss 108604.267578125
2022-03-03 12:59:58,716:INFO:Epoch 97, Training loss 108418.998046875, Validation loss 108609.81640625
2022-03-03 13:00:01,160:INFO:Epoch 98, Training loss 108419.8671875, Validation loss 108605.12109375
2022-03-03 13:00:03,631:INFO:Epoch 99, Training loss 108419.060546875, Validation loss 108606.109375
2022-03-03 13:00:06,203:INFO:Epoch 100, Training loss 108418.96875, Validation loss 108607.0546875
2022-03-03 13:00:08,691:INFO:Epoch 101, Training loss 108417.357421875, Validation loss 108601.828125
2022-03-03 13:00:11,083:INFO:Epoch 102, Training loss 108418.111328125, Validation loss 108604.02734375
2022-03-03 13:00:13,626:INFO:Epoch 103, Training loss 108416.751953125, Validation loss 108612.923828125
2022-03-03 13:00:16,041:INFO:Epoch 104, Training loss 108419.0703125, Validation loss 108606.921875
2022-03-03 13:00:18,551:INFO:Epoch 105, Training loss 108416.05078125, Validation loss 108602.5546875
2022-03-03 13:00:20,947:INFO:Epoch 106, Training loss 108417.525390625, Validation loss 108602.705078125
2022-03-03 13:00:23,460:INFO:Epoch 107, Training loss 108414.763671875, Validation loss 108609.77734375
2022-03-03 13:00:25,888:INFO:Epoch 108, Training loss 108416.734375, Validation loss 108614.07421875
2022-03-03 13:00:28,306:INFO:Epoch 109, Training loss 108417.0390625, Validation loss 108604.51953125
2022-03-03 13:00:30,686:INFO:Epoch 110, Training loss 108415.671875, Validation loss 108605.490234375
2022-03-03 13:00:33,119:INFO:Epoch 111, Training loss 108414.423828125, Validation loss 108604.84375
2022-03-03 13:00:35,481:INFO:Epoch 112, Training loss 108413.60546875, Validation loss 108608.259765625
2022-03-03 13:00:37,809:INFO:Epoch 113, Training loss 108414.78515625, Validation loss 108608.369140625
2022-03-03 13:00:40,306:INFO:Epoch 114, Training loss 108413.05859375, Validation loss 108602.669921875
2022-03-03 13:00:42,714:INFO:Epoch 115, Training loss 108417.009765625, Validation loss 108610.85546875
2022-03-03 13:00:45,087:INFO:Epoch 116, Training loss 108411.779296875, Validation loss 108603.640625
2022-03-03 13:00:47,402:INFO:Epoch 117, Training loss 108412.591796875, Validation loss 108604.900390625
2022-03-03 13:00:49,956:INFO:Epoch 118, Training loss 108411.4609375, Validation loss 108606.373046875
2022-03-03 13:00:52,341:INFO:Epoch 119, Training loss 108411.525390625, Validation loss 108611.564453125
2022-03-03 13:00:52,347:INFO:Finished training
