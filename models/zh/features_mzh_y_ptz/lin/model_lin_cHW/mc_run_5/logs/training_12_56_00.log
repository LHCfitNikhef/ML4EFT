2022-03-03 12:56:00,630:INFO:All directories created, ready to load the data
2022-03-03 12:56:00,700:INFO:Dataset loaded from /data/theorie/jthoeve/training_data/zh/features_mzh_y_ptz_v2/lin/cHW/events_5.pkl.gz
2022-03-03 12:56:00,730:INFO:Dataset loaded from /data/theorie/jthoeve/training_data/zh/features_mzh_y_ptz_v2/sm/events_5.pkl.gz
2022-03-03 12:56:03,121:INFO:Epoch 1, Training loss 206310.28515625, Validation loss 198083.03125
2022-03-03 12:56:05,532:INFO:Epoch 2, Training loss 189836.63671875, Validation loss 178161.60546875
2022-03-03 12:56:07,870:INFO:Epoch 3, Training loss 171144.89453125, Validation loss 161448.521484375
2022-03-03 12:56:10,223:INFO:Epoch 4, Training loss 155794.478515625, Validation loss 148084.75
2022-03-03 12:56:12,564:INFO:Epoch 5, Training loss 143405.6171875, Validation loss 136922.224609375
2022-03-03 12:56:14,960:INFO:Epoch 6, Training loss 132685.193359375, Validation loss 126807.880859375
2022-03-03 12:56:17,313:INFO:Epoch 7, Training loss 123053.587890625, Validation loss 118308.900390625
2022-03-03 12:56:19,653:INFO:Epoch 8, Training loss 115679.84765625, Validation loss 112638.537109375
2022-03-03 12:56:22,013:INFO:Epoch 9, Training loss 111244.28515625, Validation loss 110038.111328125
2022-03-03 12:56:24,400:INFO:Epoch 10, Training loss 109659.46875, Validation loss 109634.17578125
2022-03-03 12:56:26,767:INFO:Epoch 11, Training loss 109650.595703125, Validation loss 109903.33984375
2022-03-03 12:56:29,096:INFO:Epoch 12, Training loss 109854.95703125, Validation loss 109896.931640625
2022-03-03 12:56:31,461:INFO:Epoch 13, Training loss 109706.1640625, Validation loss 109608.35546875
2022-03-03 12:56:33,844:INFO:Epoch 14, Training loss 109451.80078125, Validation loss 109473.052734375
2022-03-03 12:56:36,222:INFO:Epoch 15, Training loss 109408.2109375, Validation loss 109510.033203125
2022-03-03 12:56:38,550:INFO:Epoch 16, Training loss 109412.669921875, Validation loss 109449.63671875
2022-03-03 12:56:40,932:INFO:Epoch 17, Training loss 109349.44921875, Validation loss 109402.193359375
2022-03-03 12:56:43,260:INFO:Epoch 18, Training loss 109324.28125, Validation loss 109389.935546875
2022-03-03 12:56:45,675:INFO:Epoch 19, Training loss 109310.724609375, Validation loss 109363.626953125
2022-03-03 12:56:47,998:INFO:Epoch 20, Training loss 109281.361328125, Validation loss 109329.654296875
2022-03-03 12:56:50,367:INFO:Epoch 21, Training loss 109259.68359375, Validation loss 109315.197265625
2022-03-03 12:56:52,699:INFO:Epoch 22, Training loss 109242.759765625, Validation loss 109291.537109375
2022-03-03 12:56:55,108:INFO:Epoch 23, Training loss 109222.173828125, Validation loss 109271.87890625
2022-03-03 12:56:57,446:INFO:Epoch 24, Training loss 109205.708984375, Validation loss 109251.947265625
2022-03-03 12:56:59,795:INFO:Epoch 25, Training loss 109186.57421875, Validation loss 109231.490234375
2022-03-03 12:57:02,139:INFO:Epoch 26, Training loss 109168.376953125, Validation loss 109211.140625
2022-03-03 12:57:04,549:INFO:Epoch 27, Training loss 109149.265625, Validation loss 109189.046875
2022-03-03 12:57:06,899:INFO:Epoch 28, Training loss 109128.88671875, Validation loss 109166.935546875
2022-03-03 12:57:09,242:INFO:Epoch 29, Training loss 109107.544921875, Validation loss 109144.26953125
2022-03-03 12:57:11,596:INFO:Epoch 30, Training loss 109086.072265625, Validation loss 109119.41796875
2022-03-03 12:57:13,987:INFO:Epoch 31, Training loss 109060.552734375, Validation loss 109091.55078125
2022-03-03 12:57:16,350:INFO:Epoch 32, Training loss 109033.029296875, Validation loss 109059.865234375
2022-03-03 12:57:18,680:INFO:Epoch 33, Training loss 109000.71484375, Validation loss 109023.693359375
2022-03-03 12:57:21,048:INFO:Epoch 34, Training loss 108963.83203125, Validation loss 108982.033203125
2022-03-03 12:57:23,427:INFO:Epoch 35, Training loss 108923.908203125, Validation loss 108936.755859375
2022-03-03 12:57:25,803:INFO:Epoch 36, Training loss 108878.5625, Validation loss 108887.478515625
2022-03-03 12:57:28,123:INFO:Epoch 37, Training loss 108831.796875, Validation loss 108835.716796875
2022-03-03 12:57:30,508:INFO:Epoch 38, Training loss 108781.474609375, Validation loss 108785.765625
2022-03-03 12:57:32,833:INFO:Epoch 39, Training loss 108737.25, Validation loss 108736.765625
2022-03-03 12:57:35,255:INFO:Epoch 40, Training loss 108694.30859375, Validation loss 108696.259765625
2022-03-03 12:57:37,582:INFO:Epoch 41, Training loss 108657.60546875, Validation loss 108666.90625
2022-03-03 12:57:39,964:INFO:Epoch 42, Training loss 108631.29296875, Validation loss 108645.076171875
2022-03-03 12:57:42,295:INFO:Epoch 43, Training loss 108609.888671875, Validation loss 108629.419921875
2022-03-03 12:57:44,704:INFO:Epoch 44, Training loss 108595.37109375, Validation loss 108623.208984375
2022-03-03 12:57:47,046:INFO:Epoch 45, Training loss 108584.763671875, Validation loss 108615.53515625
2022-03-03 12:57:49,393:INFO:Epoch 46, Training loss 108577.6640625, Validation loss 108611.091796875
2022-03-03 12:57:51,742:INFO:Epoch 47, Training loss 108573.4453125, Validation loss 108609.55859375
2022-03-03 12:57:54,149:INFO:Epoch 48, Training loss 108570.576171875, Validation loss 108610.76171875
2022-03-03 12:57:56,501:INFO:Epoch 49, Training loss 108566.591796875, Validation loss 108612.318359375
2022-03-03 12:57:58,839:INFO:Epoch 50, Training loss 108564.603515625, Validation loss 108612.326171875
2022-03-03 12:58:01,194:INFO:Epoch 51, Training loss 108561.69921875, Validation loss 108611.36328125
2022-03-03 12:58:03,586:INFO:Epoch 52, Training loss 108559.14453125, Validation loss 108609.185546875
2022-03-03 12:58:05,942:INFO:Epoch 53, Training loss 108558.7265625, Validation loss 108607.259765625
2022-03-03 12:58:08,270:INFO:Epoch 54, Training loss 108556.6796875, Validation loss 108607.609375
2022-03-03 12:58:10,640:INFO:Epoch 55, Training loss 108555.7578125, Validation loss 108607.24609375
2022-03-03 12:58:13,013:INFO:Epoch 56, Training loss 108553.109375, Validation loss 108608.41015625
2022-03-03 12:58:15,386:INFO:Epoch 57, Training loss 108550.439453125, Validation loss 108607.48046875
2022-03-03 12:58:17,702:INFO:Epoch 58, Training loss 108549.724609375, Validation loss 108605.66015625
2022-03-03 12:58:20,080:INFO:Epoch 59, Training loss 108548.68359375, Validation loss 108604.103515625
2022-03-03 12:58:22,413:INFO:Epoch 60, Training loss 108546.974609375, Validation loss 108604.193359375
2022-03-03 12:58:24,832:INFO:Epoch 61, Training loss 108544.755859375, Validation loss 108605.099609375
2022-03-03 12:58:27,155:INFO:Epoch 62, Training loss 108544.146484375, Validation loss 108605.2578125
2022-03-03 12:58:29,529:INFO:Epoch 63, Training loss 108542.904296875, Validation loss 108606.267578125
2022-03-03 12:58:31,874:INFO:Epoch 64, Training loss 108541.736328125, Validation loss 108604.787109375
2022-03-03 12:58:34,294:INFO:Epoch 65, Training loss 108541.373046875, Validation loss 108605.71875
2022-03-03 12:58:36,637:INFO:Epoch 66, Training loss 108539.62890625, Validation loss 108605.603515625
2022-03-03 12:58:38,997:INFO:Epoch 67, Training loss 108538.828125, Validation loss 108606.001953125
2022-03-03 12:58:41,350:INFO:Epoch 68, Training loss 108537.388671875, Validation loss 108605.384765625
2022-03-03 12:58:43,756:INFO:Epoch 69, Training loss 108536.484375, Validation loss 108604.978515625
2022-03-03 12:58:46,106:INFO:Epoch 70, Training loss 108536.51171875, Validation loss 108604.572265625
2022-03-03 12:58:48,452:INFO:Epoch 71, Training loss 108534.970703125, Validation loss 108604.619140625
2022-03-03 12:58:50,809:INFO:Epoch 72, Training loss 108534.41015625, Validation loss 108602.376953125
2022-03-03 12:58:53,203:INFO:Epoch 73, Training loss 108533.14453125, Validation loss 108604.607421875
2022-03-03 12:58:55,562:INFO:Epoch 74, Training loss 108532.51953125, Validation loss 108604.654296875
2022-03-03 12:58:57,895:INFO:Epoch 75, Training loss 108532.609375, Validation loss 108604.359375
2022-03-03 12:59:00,264:INFO:Epoch 76, Training loss 108530.642578125, Validation loss 108602.798828125
2022-03-03 12:59:02,648:INFO:Epoch 77, Training loss 108529.49609375, Validation loss 108602.740234375
2022-03-03 12:59:05,024:INFO:Epoch 78, Training loss 108529.80859375, Validation loss 108602.318359375
2022-03-03 12:59:07,341:INFO:Epoch 79, Training loss 108528.94921875, Validation loss 108602.158203125
2022-03-03 12:59:09,729:INFO:Epoch 80, Training loss 108528.826171875, Validation loss 108602.349609375
2022-03-03 12:59:12,069:INFO:Epoch 81, Training loss 108526.90625, Validation loss 108602.263671875
2022-03-03 12:59:14,482:INFO:Epoch 82, Training loss 108527.330078125, Validation loss 108601.349609375
2022-03-03 12:59:16,808:INFO:Epoch 83, Training loss 108526.408203125, Validation loss 108604.740234375
2022-03-03 12:59:19,179:INFO:Epoch 84, Training loss 108525.07421875, Validation loss 108603.767578125
2022-03-03 12:59:21,517:INFO:Epoch 85, Training loss 108524.85546875, Validation loss 108601.78515625
2022-03-03 12:59:23,933:INFO:Epoch 86, Training loss 108524.015625, Validation loss 108603.130859375
2022-03-03 12:59:26,271:INFO:Epoch 87, Training loss 108523.83984375, Validation loss 108604.02734375
2022-03-03 12:59:28,623:INFO:Epoch 88, Training loss 108522.751953125, Validation loss 108601.087890625
2022-03-03 12:59:30,978:INFO:Epoch 89, Training loss 108522.69921875, Validation loss 108601.310546875
2022-03-03 12:59:33,383:INFO:Epoch 90, Training loss 108521.939453125, Validation loss 108603.021484375
2022-03-03 12:59:35,736:INFO:Epoch 91, Training loss 108522.73046875, Validation loss 108602.90234375
2022-03-03 12:59:38,082:INFO:Epoch 92, Training loss 108521.15625, Validation loss 108601.61328125
2022-03-03 12:59:40,439:INFO:Epoch 93, Training loss 108521.779296875, Validation loss 108601.9375
2022-03-03 12:59:42,827:INFO:Epoch 94, Training loss 108520.48828125, Validation loss 108603.23046875
2022-03-03 12:59:45,191:INFO:Epoch 95, Training loss 108519.779296875, Validation loss 108602.6875
2022-03-03 12:59:47,521:INFO:Epoch 96, Training loss 108520.0, Validation loss 108601.931640625
2022-03-03 12:59:49,883:INFO:Epoch 97, Training loss 108520.298828125, Validation loss 108601.447265625
2022-03-03 12:59:52,266:INFO:Epoch 98, Training loss 108518.69140625, Validation loss 108602.08984375
2022-03-03 12:59:54,632:INFO:Epoch 99, Training loss 108518.984375, Validation loss 108603.537109375
2022-03-03 12:59:56,948:INFO:Epoch 100, Training loss 108518.2578125, Validation loss 108602.392578125
2022-03-03 12:59:59,328:INFO:Epoch 101, Training loss 108518.861328125, Validation loss 108601.84765625
2022-03-03 13:00:01,653:INFO:Epoch 102, Training loss 108518.640625, Validation loss 108601.923828125
2022-03-03 13:00:04,075:INFO:Epoch 103, Training loss 108518.615234375, Validation loss 108604.248046875
2022-03-03 13:00:06,401:INFO:Epoch 104, Training loss 108519.80859375, Validation loss 108605.037109375
2022-03-03 13:00:08,779:INFO:Epoch 105, Training loss 108516.9140625, Validation loss 108604.201171875
2022-03-03 13:00:11,116:INFO:Epoch 106, Training loss 108518.232421875, Validation loss 108604.55859375
2022-03-03 13:00:13,529:INFO:Epoch 107, Training loss 108515.84765625, Validation loss 108601.5390625
2022-03-03 13:00:15,867:INFO:Epoch 108, Training loss 108516.525390625, Validation loss 108601.6484375
2022-03-03 13:00:18,224:INFO:Epoch 109, Training loss 108516.591796875, Validation loss 108604.251953125
2022-03-03 13:00:20,572:INFO:Epoch 110, Training loss 108516.900390625, Validation loss 108603.54296875
2022-03-03 13:00:22,977:INFO:Epoch 111, Training loss 108516.24609375, Validation loss 108603.501953125
2022-03-03 13:00:25,333:INFO:Epoch 112, Training loss 108515.736328125, Validation loss 108602.71484375
2022-03-03 13:00:27,681:INFO:Epoch 113, Training loss 108516.205078125, Validation loss 108603.37890625
2022-03-03 13:00:30,035:INFO:Epoch 114, Training loss 108514.4296875, Validation loss 108604.12109375
2022-03-03 13:00:32,431:INFO:Epoch 115, Training loss 108514.25390625, Validation loss 108603.83984375
2022-03-03 13:00:34,787:INFO:Epoch 116, Training loss 108513.75390625, Validation loss 108604.6875
2022-03-03 13:00:37,113:INFO:Epoch 117, Training loss 108515.37109375, Validation loss 108605.802734375
2022-03-03 13:00:39,482:INFO:Epoch 118, Training loss 108513.498046875, Validation loss 108603.287109375
2022-03-03 13:00:41,869:INFO:Epoch 119, Training loss 108513.62890625, Validation loss 108601.486328125
2022-03-03 13:00:44,246:INFO:Epoch 120, Training loss 108513.796875, Validation loss 108604.9375
2022-03-03 13:00:46,568:INFO:Epoch 121, Training loss 108511.998046875, Validation loss 108604.43359375
2022-03-03 13:00:48,948:INFO:Epoch 122, Training loss 108512.3984375, Validation loss 108603.73828125
2022-03-03 13:00:51,272:INFO:Epoch 123, Training loss 108511.53515625, Validation loss 108602.798828125
2022-03-03 13:00:53,692:INFO:Epoch 124, Training loss 108510.763671875, Validation loss 108603.2421875
2022-03-03 13:00:56,020:INFO:Epoch 125, Training loss 108511.966796875, Validation loss 108602.548828125
2022-03-03 13:00:58,390:INFO:Epoch 126, Training loss 108510.44140625, Validation loss 108603.51953125
2022-03-03 13:01:00,722:INFO:Epoch 127, Training loss 108510.0078125, Validation loss 108604.08203125
2022-03-03 13:01:03,132:INFO:Epoch 128, Training loss 108510.03515625, Validation loss 108606.58203125
2022-03-03 13:01:05,471:INFO:Epoch 129, Training loss 108510.44921875, Validation loss 108604.896484375
2022-03-03 13:01:07,828:INFO:Epoch 130, Training loss 108508.947265625, Validation loss 108603.74609375
2022-03-03 13:01:10,169:INFO:Epoch 131, Training loss 108510.833984375, Validation loss 108604.712890625
2022-03-03 13:01:12,568:INFO:Epoch 132, Training loss 108508.78125, Validation loss 108603.4765625
2022-03-03 13:01:14,917:INFO:Epoch 133, Training loss 108512.3359375, Validation loss 108610.81640625
2022-03-03 13:01:17,257:INFO:Epoch 134, Training loss 108513.197265625, Validation loss 108606.41015625
2022-03-03 13:01:19,615:INFO:Epoch 135, Training loss 108510.5078125, Validation loss 108605.779296875
2022-03-03 13:01:22,011:INFO:Epoch 136, Training loss 108510.86328125, Validation loss 108607.95703125
2022-03-03 13:01:24,368:INFO:Epoch 137, Training loss 108510.556640625, Validation loss 108605.220703125
2022-03-03 13:01:26,699:INFO:Epoch 138, Training loss 108507.654296875, Validation loss 108603.98046875
2022-03-03 13:01:26,750:INFO:Finished training
