2022-03-03 12:56:00,009:INFO:All directories created, ready to load the data
2022-03-03 12:56:00,081:INFO:Dataset loaded from /data/theorie/jthoeve/training_data/zh/features_mzh_y_ptz_v2/lin/cHW/events_16.pkl.gz
2022-03-03 12:56:00,136:INFO:Dataset loaded from /data/theorie/jthoeve/training_data/zh/features_mzh_y_ptz_v2/sm/events_16.pkl.gz
2022-03-03 12:56:02,511:INFO:Epoch 1, Training loss 207977.2265625, Validation loss 207977.2265625
2022-03-03 12:56:04,877:INFO:Epoch 2, Training loss 207977.2265625, Validation loss 207977.2265625
2022-03-03 12:56:07,179:INFO:Epoch 3, Training loss 207977.2265625, Validation loss 207977.2265625
2022-03-03 12:56:09,495:INFO:Epoch 4, Training loss 207977.2265625, Validation loss 207977.2265625
2022-03-03 12:56:11,792:INFO:Epoch 5, Training loss 207977.2265625, Validation loss 207977.2265625
2022-03-03 12:56:14,143:INFO:Epoch 6, Training loss 207977.2265625, Validation loss 207977.2265625
2022-03-03 12:56:16,452:INFO:Epoch 7, Training loss 207977.2265625, Validation loss 207977.2265625
2022-03-03 12:56:18,746:INFO:Epoch 8, Training loss 207977.2265625, Validation loss 207977.2265625
2022-03-03 12:56:21,065:INFO:Epoch 9, Training loss 207977.2265625, Validation loss 207977.2265625
2022-03-03 12:56:23,416:INFO:Epoch 10, Training loss 207977.2265625, Validation loss 207977.2265625
2022-03-03 12:56:25,737:INFO:Epoch 11, Training loss 207977.2265625, Validation loss 207977.2265625
2022-03-03 12:56:25,740:INFO:Detected stagant training, reset the weights
2022-03-03 12:56:28,031:INFO:Epoch 12, Training loss 125074.953125, Validation loss 121263.265625
2022-03-03 12:56:30,344:INFO:Epoch 13, Training loss 118778.240234375, Validation loss 115304.908203125
2022-03-03 12:56:32,678:INFO:Epoch 14, Training loss 113426.384765625, Validation loss 111155.23828125
2022-03-03 12:56:35,015:INFO:Epoch 15, Training loss 110305.626953125, Validation loss 109611.23828125
2022-03-03 12:56:37,295:INFO:Epoch 16, Training loss 109609.013671875, Validation loss 109813.564453125
2022-03-03 12:56:39,634:INFO:Epoch 17, Training loss 109839.4609375, Validation loss 109808.53515625
2022-03-03 12:56:41,914:INFO:Epoch 18, Training loss 109645.357421875, Validation loss 109431.609375
2022-03-03 12:56:44,284:INFO:Epoch 19, Training loss 109316.603515625, Validation loss 109205.728515625
2022-03-03 12:56:46,569:INFO:Epoch 20, Training loss 109172.41796875, Validation loss 109138.98046875
2022-03-03 12:56:48,893:INFO:Epoch 21, Training loss 109123.462890625, Validation loss 109087.267578125
2022-03-03 12:56:51,186:INFO:Epoch 22, Training loss 109066.830078125, Validation loss 109020.755859375
2022-03-03 12:56:53,556:INFO:Epoch 23, Training loss 109006.8203125, Validation loss 108964.591796875
2022-03-03 12:56:55,850:INFO:Epoch 24, Training loss 108960.59765625, Validation loss 108912.80078125
2022-03-03 12:56:58,164:INFO:Epoch 25, Training loss 108913.712890625, Validation loss 108867.09375
2022-03-03 12:57:00,464:INFO:Epoch 26, Training loss 108871.177734375, Validation loss 108822.208984375
2022-03-03 12:57:02,826:INFO:Epoch 27, Training loss 108828.810546875, Validation loss 108780.296875
2022-03-03 12:57:05,140:INFO:Epoch 28, Training loss 108787.705078125, Validation loss 108741.322265625
2022-03-03 12:57:07,434:INFO:Epoch 29, Training loss 108751.943359375, Validation loss 108705.3359375
2022-03-03 12:57:09,752:INFO:Epoch 30, Training loss 108719.91015625, Validation loss 108674.173828125
2022-03-03 12:57:12,090:INFO:Epoch 31, Training loss 108693.720703125, Validation loss 108648.90625
2022-03-03 12:57:14,413:INFO:Epoch 32, Training loss 108673.3203125, Validation loss 108629.8359375
2022-03-03 12:57:16,698:INFO:Epoch 33, Training loss 108656.755859375, Validation loss 108616.6328125
2022-03-03 12:57:19,019:INFO:Epoch 34, Training loss 108648.771484375, Validation loss 108607.943359375
2022-03-03 12:57:21,359:INFO:Epoch 35, Training loss 108642.197265625, Validation loss 108602.513671875
2022-03-03 12:57:23,682:INFO:Epoch 36, Training loss 108638.697265625, Validation loss 108600.15625
2022-03-03 12:57:25,954:INFO:Epoch 37, Training loss 108635.265625, Validation loss 108597.20703125
2022-03-03 12:57:28,288:INFO:Epoch 38, Training loss 108633.33984375, Validation loss 108594.541015625
2022-03-03 12:57:30,568:INFO:Epoch 39, Training loss 108631.6328125, Validation loss 108592.189453125
2022-03-03 12:57:32,950:INFO:Epoch 40, Training loss 108629.45703125, Validation loss 108592.474609375
2022-03-03 12:57:35,239:INFO:Epoch 41, Training loss 108627.98828125, Validation loss 108590.923828125
2022-03-03 12:57:37,572:INFO:Epoch 42, Training loss 108626.58984375, Validation loss 108590.271484375
2022-03-03 12:57:39,867:INFO:Epoch 43, Training loss 108625.216796875, Validation loss 108590.12890625
2022-03-03 12:57:42,237:INFO:Epoch 44, Training loss 108623.892578125, Validation loss 108588.78515625
2022-03-03 12:57:44,535:INFO:Epoch 45, Training loss 108623.052734375, Validation loss 108587.05078125
2022-03-03 12:57:46,843:INFO:Epoch 46, Training loss 108621.466796875, Validation loss 108587.22265625
2022-03-03 12:57:49,148:INFO:Epoch 47, Training loss 108620.447265625, Validation loss 108586.927734375
2022-03-03 12:57:51,508:INFO:Epoch 48, Training loss 108619.455078125, Validation loss 108586.068359375
2022-03-03 12:57:53,820:INFO:Epoch 49, Training loss 108618.84765625, Validation loss 108585.36328125
2022-03-03 12:57:56,121:INFO:Epoch 50, Training loss 108617.93359375, Validation loss 108584.90625
2022-03-03 12:57:58,432:INFO:Epoch 51, Training loss 108617.0625, Validation loss 108584.90625
2022-03-03 12:58:00,772:INFO:Epoch 52, Training loss 108616.068359375, Validation loss 108585.115234375
2022-03-03 12:58:03,091:INFO:Epoch 53, Training loss 108614.759765625, Validation loss 108583.435546875
2022-03-03 12:58:05,384:INFO:Epoch 54, Training loss 108615.935546875, Validation loss 108582.462890625
2022-03-03 12:58:07,710:INFO:Epoch 55, Training loss 108614.40625, Validation loss 108582.599609375
2022-03-03 12:58:10,047:INFO:Epoch 56, Training loss 108614.658203125, Validation loss 108583.6875
2022-03-03 12:58:12,374:INFO:Epoch 57, Training loss 108612.32421875, Validation loss 108582.921875
2022-03-03 12:58:14,649:INFO:Epoch 58, Training loss 108612.0234375, Validation loss 108581.15234375
2022-03-03 12:58:16,986:INFO:Epoch 59, Training loss 108612.4296875, Validation loss 108581.87109375
2022-03-03 12:58:19,273:INFO:Epoch 60, Training loss 108611.064453125, Validation loss 108580.92578125
2022-03-03 12:58:21,647:INFO:Epoch 61, Training loss 108610.38671875, Validation loss 108581.609375
2022-03-03 12:58:23,939:INFO:Epoch 62, Training loss 108609.333984375, Validation loss 108581.705078125
2022-03-03 12:58:26,271:INFO:Epoch 63, Training loss 108610.009765625, Validation loss 108581.115234375
2022-03-03 12:58:28,571:INFO:Epoch 64, Training loss 108609.478515625, Validation loss 108580.55859375
2022-03-03 12:58:30,947:INFO:Epoch 65, Training loss 108607.83203125, Validation loss 108580.92578125
2022-03-03 12:58:33,246:INFO:Epoch 66, Training loss 108608.25, Validation loss 108581.4765625
2022-03-03 12:58:35,563:INFO:Epoch 67, Training loss 108606.90234375, Validation loss 108580.4609375
2022-03-03 12:58:37,868:INFO:Epoch 68, Training loss 108607.1953125, Validation loss 108579.861328125
2022-03-03 12:58:40,226:INFO:Epoch 69, Training loss 108606.013671875, Validation loss 108580.998046875
2022-03-03 12:58:42,535:INFO:Epoch 70, Training loss 108605.78515625, Validation loss 108581.171875
2022-03-03 12:58:44,839:INFO:Epoch 71, Training loss 108605.482421875, Validation loss 108579.912109375
2022-03-03 12:58:47,153:INFO:Epoch 72, Training loss 108605.22265625, Validation loss 108580.24609375
2022-03-03 12:58:49,499:INFO:Epoch 73, Training loss 108604.20703125, Validation loss 108580.77734375
2022-03-03 12:58:51,821:INFO:Epoch 74, Training loss 108603.845703125, Validation loss 108580.77734375
2022-03-03 12:58:54,111:INFO:Epoch 75, Training loss 108603.30859375, Validation loss 108579.91796875
2022-03-03 12:58:56,429:INFO:Epoch 76, Training loss 108602.78515625, Validation loss 108580.853515625
2022-03-03 12:58:58,766:INFO:Epoch 77, Training loss 108602.697265625, Validation loss 108580.951171875
2022-03-03 12:59:01,093:INFO:Epoch 78, Training loss 108602.20703125, Validation loss 108580.626953125
2022-03-03 12:59:03,368:INFO:Epoch 79, Training loss 108601.3046875, Validation loss 108580.048828125
2022-03-03 12:59:05,701:INFO:Epoch 80, Training loss 108602.916015625, Validation loss 108581.27734375
2022-03-03 12:59:07,983:INFO:Epoch 81, Training loss 108601.19140625, Validation loss 108580.021484375
2022-03-03 12:59:10,358:INFO:Epoch 82, Training loss 108602.111328125, Validation loss 108581.509765625
2022-03-03 12:59:12,640:INFO:Epoch 83, Training loss 108601.8125, Validation loss 108581.77734375
2022-03-03 12:59:14,966:INFO:Epoch 84, Training loss 108600.55078125, Validation loss 108580.263671875
2022-03-03 12:59:17,253:INFO:Epoch 85, Training loss 108600.28515625, Validation loss 108580.556640625
2022-03-03 12:59:19,621:INFO:Epoch 86, Training loss 108599.109375, Validation loss 108581.767578125
2022-03-03 12:59:21,918:INFO:Epoch 87, Training loss 108599.11328125, Validation loss 108582.07421875
2022-03-03 12:59:24,230:INFO:Epoch 88, Training loss 108598.638671875, Validation loss 108580.943359375
2022-03-03 12:59:26,528:INFO:Epoch 89, Training loss 108598.59765625, Validation loss 108580.8359375
2022-03-03 12:59:28,906:INFO:Epoch 90, Training loss 108598.154296875, Validation loss 108582.234375
2022-03-03 12:59:31,212:INFO:Epoch 91, Training loss 108597.955078125, Validation loss 108581.564453125
2022-03-03 12:59:33,518:INFO:Epoch 92, Training loss 108597.64453125, Validation loss 108582.173828125
2022-03-03 12:59:35,831:INFO:Epoch 93, Training loss 108597.02734375, Validation loss 108581.373046875
2022-03-03 12:59:38,179:INFO:Epoch 94, Training loss 108596.5234375, Validation loss 108582.11328125
2022-03-03 12:59:40,495:INFO:Epoch 95, Training loss 108596.873046875, Validation loss 108581.13671875
2022-03-03 12:59:42,782:INFO:Epoch 96, Training loss 108595.763671875, Validation loss 108582.068359375
2022-03-03 12:59:45,108:INFO:Epoch 97, Training loss 108596.01953125, Validation loss 108582.103515625
2022-03-03 12:59:47,446:INFO:Epoch 98, Training loss 108595.701171875, Validation loss 108582.326171875
2022-03-03 12:59:49,777:INFO:Epoch 99, Training loss 108596.048828125, Validation loss 108581.40625
2022-03-03 12:59:52,054:INFO:Epoch 100, Training loss 108594.486328125, Validation loss 108583.552734375
2022-03-03 12:59:54,387:INFO:Epoch 101, Training loss 108595.048828125, Validation loss 108583.154296875
2022-03-03 12:59:56,671:INFO:Epoch 102, Training loss 108594.31640625, Validation loss 108582.412109375
2022-03-03 12:59:59,052:INFO:Epoch 103, Training loss 108593.14453125, Validation loss 108581.57421875
2022-03-03 13:00:01,335:INFO:Epoch 104, Training loss 108592.287109375, Validation loss 108582.697265625
2022-03-03 13:00:03,674:INFO:Epoch 105, Training loss 108593.3671875, Validation loss 108583.279296875
2022-03-03 13:00:05,971:INFO:Epoch 106, Training loss 108592.0625, Validation loss 108582.455078125
2022-03-03 13:00:08,337:INFO:Epoch 107, Training loss 108591.8125, Validation loss 108582.55078125
2022-03-03 13:00:10,634:INFO:Epoch 108, Training loss 108592.755859375, Validation loss 108582.82421875
2022-03-03 13:00:12,942:INFO:Epoch 109, Training loss 108592.259765625, Validation loss 108584.26171875
2022-03-03 13:00:15,244:INFO:Epoch 110, Training loss 108591.078125, Validation loss 108583.2578125
2022-03-03 13:00:17,607:INFO:Epoch 111, Training loss 108590.001953125, Validation loss 108583.05078125
2022-03-03 13:00:19,918:INFO:Epoch 112, Training loss 108590.359375, Validation loss 108582.8359375
2022-03-03 13:00:22,222:INFO:Epoch 113, Training loss 108589.662109375, Validation loss 108584.3046875
2022-03-03 13:00:24,537:INFO:Epoch 114, Training loss 108589.9375, Validation loss 108583.37109375
2022-03-03 13:00:26,887:INFO:Epoch 115, Training loss 108589.494140625, Validation loss 108584.029296875
2022-03-03 13:00:29,210:INFO:Epoch 116, Training loss 108590.482421875, Validation loss 108582.740234375
2022-03-03 13:00:31,495:INFO:Epoch 117, Training loss 108591.119140625, Validation loss 108585.953125
2022-03-03 13:00:33,823:INFO:Epoch 118, Training loss 108588.947265625, Validation loss 108584.3203125
2022-03-03 13:00:33,829:INFO:Finished training
