2022-01-24 14:09:39,180:INFO:All directories created, ready to load the data
2022-01-24 14:09:39,262:INFO:Dataset loaded from /data/theorie/jthoeve/event_generation/events_high_stats/pT/lin/cHq3/events_21.npy
2022-01-24 14:09:39,268:INFO:Dataset loaded from /data/theorie/jthoeve/event_generation/events_high_stats/pT/sm/events_21.npy
2022-01-24 14:09:41,676:INFO:Epoch 1, Training loss 84641.2109375, Validation loss 84641.2109375
2022-01-24 14:09:44,072:INFO:Epoch 2, Training loss 84641.2109375, Validation loss 84641.2109375
2022-01-24 14:09:46,441:INFO:Epoch 3, Training loss 84641.2109375, Validation loss 84641.2109375
2022-01-24 14:09:48,847:INFO:Epoch 4, Training loss 84641.2109375, Validation loss 84641.2109375
2022-01-24 14:09:51,225:INFO:Epoch 5, Training loss 84641.2109375, Validation loss 84641.2109375
2022-01-24 14:09:53,592:INFO:Epoch 6, Training loss 84641.2109375, Validation loss 84641.2109375
2022-01-24 14:09:55,966:INFO:Epoch 7, Training loss 84641.2109375, Validation loss 84641.2109375
2022-01-24 14:09:58,360:INFO:Epoch 8, Training loss 84641.2109375, Validation loss 84641.2109375
2022-01-24 14:10:00,746:INFO:Epoch 9, Training loss 84641.2109375, Validation loss 84641.2109375
2022-01-24 14:10:03,103:INFO:Epoch 10, Training loss 84641.2109375, Validation loss 84641.2109375
2022-01-24 14:10:05,497:INFO:Epoch 11, Training loss 84641.2109375, Validation loss 84641.2109375
2022-01-24 14:10:05,501:INFO:Detected stagant training, reset the weights
2022-01-24 14:10:07,882:INFO:Epoch 12, Training loss 84632.10546875, Validation loss 84608.873046875
2022-01-24 14:10:10,272:INFO:Epoch 13, Training loss 84500.017578125, Validation loss 84147.642578125
2022-01-24 14:10:12,628:INFO:Epoch 14, Training loss 82156.5732421875, Validation loss 76787.6953125
2022-01-24 14:10:15,030:INFO:Epoch 15, Training loss 75114.33203125, Validation loss 74679.0517578125
2022-01-24 14:10:17,383:INFO:Epoch 16, Training loss 75069.8359375, Validation loss 75216.40234375
2022-01-24 14:10:19,802:INFO:Epoch 17, Training loss 74864.990234375, Validation loss 74275.03515625
2022-01-24 14:10:22,184:INFO:Epoch 18, Training loss 74036.34765625, Validation loss 73837.548828125
2022-01-24 14:10:24,577:INFO:Epoch 19, Training loss 73869.7578125, Validation loss 73902.30078125
2022-01-24 14:10:26,941:INFO:Epoch 20, Training loss 73888.1025390625, Validation loss 73816.4140625
2022-01-24 14:10:29,362:INFO:Epoch 21, Training loss 73785.9521484375, Validation loss 73749.0390625
2022-01-24 14:10:31,725:INFO:Epoch 22, Training loss 73762.89453125, Validation loss 73764.673828125
2022-01-24 14:10:34,105:INFO:Epoch 23, Training loss 73767.2060546875, Validation loss 73747.4013671875
2022-01-24 14:10:36,483:INFO:Epoch 24, Training loss 73751.7734375, Validation loss 73748.71875
2022-01-24 14:10:38,891:INFO:Epoch 25, Training loss 73753.7119140625, Validation loss 73744.83984375
2022-01-24 14:10:41,282:INFO:Epoch 26, Training loss 73747.779296875, Validation loss 73744.4228515625
2022-01-24 14:10:43,654:INFO:Epoch 27, Training loss 73747.705078125, Validation loss 73744.060546875
2022-01-24 14:10:46,040:INFO:Epoch 28, Training loss 73746.0556640625, Validation loss 73743.73828125
2022-01-24 14:10:48,443:INFO:Epoch 29, Training loss 73745.7607421875, Validation loss 73743.537109375
2022-01-24 14:10:50,840:INFO:Epoch 30, Training loss 73744.763671875, Validation loss 73742.9970703125
2022-01-24 14:10:53,205:INFO:Epoch 31, Training loss 73744.2431640625, Validation loss 73742.822265625
2022-01-24 14:10:55,605:INFO:Epoch 32, Training loss 73743.56640625, Validation loss 73742.6650390625
2022-01-24 14:10:57,999:INFO:Epoch 33, Training loss 73743.265625, Validation loss 73742.7080078125
2022-01-24 14:11:00,400:INFO:Epoch 34, Training loss 73742.7509765625, Validation loss 73742.701171875
2022-01-24 14:11:02,759:INFO:Epoch 35, Training loss 73742.474609375, Validation loss 73742.71484375
2022-01-24 14:11:05,154:INFO:Epoch 36, Training loss 73742.0888671875, Validation loss 73742.87890625
2022-01-24 14:11:07,512:INFO:Epoch 37, Training loss 73741.8359375, Validation loss 73742.958984375
2022-01-24 14:11:09,940:INFO:Epoch 38, Training loss 73741.4345703125, Validation loss 73743.138671875
2022-01-24 14:11:12,299:INFO:Epoch 39, Training loss 73741.0302734375, Validation loss 73743.302734375
2022-01-24 14:11:14,701:INFO:Epoch 40, Training loss 73740.6455078125, Validation loss 73743.3583984375
2022-01-24 14:11:17,064:INFO:Epoch 41, Training loss 73740.5048828125, Validation loss 73743.458984375
2022-01-24 14:11:19,487:INFO:Epoch 42, Training loss 73740.1591796875, Validation loss 73743.4384765625
2022-01-24 14:11:21,865:INFO:Epoch 43, Training loss 73739.9345703125, Validation loss 73743.443359375
2022-01-24 14:11:24,245:INFO:Epoch 44, Training loss 73739.6494140625, Validation loss 73743.58984375
2022-01-24 14:11:26,623:INFO:Epoch 45, Training loss 73739.423828125, Validation loss 73743.93359375
2022-01-24 14:11:29,036:INFO:Epoch 46, Training loss 73739.1337890625, Validation loss 73744.435546875
2022-01-24 14:11:31,416:INFO:Epoch 47, Training loss 73738.8515625, Validation loss 73744.7060546875
2022-01-24 14:11:33,787:INFO:Epoch 48, Training loss 73738.548828125, Validation loss 73744.73046875
2022-01-24 14:11:36,174:INFO:Epoch 49, Training loss 73738.4052734375, Validation loss 73744.6591796875
2022-01-24 14:11:38,569:INFO:Epoch 50, Training loss 73738.0595703125, Validation loss 73744.8974609375
2022-01-24 14:11:40,982:INFO:Epoch 51, Training loss 73737.7763671875, Validation loss 73745.2412109375
2022-01-24 14:11:43,355:INFO:Epoch 52, Training loss 73737.693359375, Validation loss 73745.396484375
2022-01-24 14:11:45,749:INFO:Epoch 53, Training loss 73737.5234375, Validation loss 73745.2197265625
2022-01-24 14:11:48,139:INFO:Epoch 54, Training loss 73737.3388671875, Validation loss 73745.1494140625
2022-01-24 14:11:50,534:INFO:Epoch 55, Training loss 73737.2001953125, Validation loss 73745.603515625
2022-01-24 14:11:52,890:INFO:Epoch 56, Training loss 73736.94140625, Validation loss 73745.626953125
2022-01-24 14:11:55,297:INFO:Epoch 57, Training loss 73736.5830078125, Validation loss 73745.666015625
2022-01-24 14:11:57,685:INFO:Epoch 58, Training loss 73736.513671875, Validation loss 73745.650390625
2022-01-24 14:12:00,112:INFO:Epoch 59, Training loss 73736.525390625, Validation loss 73745.75390625
2022-01-24 14:12:02,495:INFO:Epoch 60, Training loss 73736.3857421875, Validation loss 73746.326171875
2022-01-24 14:12:04,923:INFO:Epoch 61, Training loss 73736.033203125, Validation loss 73746.3671875
2022-01-24 14:12:07,291:INFO:Epoch 62, Training loss 73736.2216796875, Validation loss 73746.470703125
2022-01-24 14:12:09,721:INFO:Epoch 63, Training loss 73735.5185546875, Validation loss 73746.421875
2022-01-24 14:12:12,102:INFO:Epoch 64, Training loss 73735.3974609375, Validation loss 73746.1787109375
2022-01-24 14:12:14,497:INFO:Epoch 65, Training loss 73735.3857421875, Validation loss 73746.2490234375
2022-01-24 14:12:16,876:INFO:Epoch 66, Training loss 73734.830078125, Validation loss 73746.7236328125
2022-01-24 14:12:19,284:INFO:Epoch 67, Training loss 73734.82421875, Validation loss 73747.2822265625
2022-01-24 14:12:21,666:INFO:Epoch 68, Training loss 73734.5732421875, Validation loss 73747.48046875
2022-01-24 14:12:24,044:INFO:Epoch 69, Training loss 73734.4365234375, Validation loss 73747.0205078125
2022-01-24 14:12:26,431:INFO:Epoch 70, Training loss 73734.2939453125, Validation loss 73747.115234375
2022-01-24 14:12:28,836:INFO:Epoch 71, Training loss 73733.81640625, Validation loss 73747.173828125
2022-01-24 14:12:31,226:INFO:Epoch 72, Training loss 73733.8486328125, Validation loss 73747.181640625
2022-01-24 14:12:33,598:INFO:Epoch 73, Training loss 73733.537109375, Validation loss 73747.572265625
2022-01-24 14:12:35,995:INFO:Epoch 74, Training loss 73733.513671875, Validation loss 73748.4365234375
2022-01-24 14:12:38,384:INFO:Epoch 75, Training loss 73733.1142578125, Validation loss 73748.4775390625
2022-01-24 14:12:40,771:INFO:Epoch 76, Training loss 73733.2373046875, Validation loss 73747.8408203125
2022-01-24 14:12:43,114:INFO:Epoch 77, Training loss 73732.3115234375, Validation loss 73747.9482421875
2022-01-24 14:12:45,497:INFO:Epoch 78, Training loss 73732.1982421875, Validation loss 73748.2763671875
2022-01-24 14:12:47,836:INFO:Epoch 79, Training loss 73731.6513671875, Validation loss 73748.8828125
2022-01-24 14:12:50,256:INFO:Epoch 80, Training loss 73731.68359375, Validation loss 73749.259765625
2022-01-24 14:12:52,604:INFO:Epoch 81, Training loss 73731.283203125, Validation loss 73748.5986328125
2022-01-24 14:12:54,974:INFO:Epoch 82, Training loss 73730.8662109375, Validation loss 73748.87890625
2022-01-24 14:12:54,981:INFO:Finished training
