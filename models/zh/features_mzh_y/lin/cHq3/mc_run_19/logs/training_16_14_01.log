2021-11-18 16:14:01,350:INFO:All directories created, ready to load the data
2021-11-18 16:14:01,384:INFO:Dataset loaded from /data/theorie/jthoeve/event_generation/events_high_stats/lin/cHq3/events_19.npy
2021-11-18 16:14:01,415:INFO:Dataset loaded from /data/theorie/jthoeve/event_generation/events_high_stats/sm/events_19.npy
2021-11-18 16:14:05,222:INFO:Epoch 1, Training loss 84716.9140625, Validation loss 84716.9140625
2021-11-18 16:14:08,917:INFO:Epoch 2, Training loss 84716.9140625, Validation loss 84716.9140625
2021-11-18 16:14:12,686:INFO:Epoch 3, Training loss 84716.9140625, Validation loss 84716.9140625
2021-11-18 16:14:16,408:INFO:Epoch 4, Training loss 84716.9140625, Validation loss 84716.9140625
2021-11-18 16:14:20,151:INFO:Epoch 5, Training loss 84716.9140625, Validation loss 84716.9140625
2021-11-18 16:14:23,728:INFO:Epoch 6, Training loss 84716.9140625, Validation loss 84716.9140625
2021-11-18 16:14:27,447:INFO:Epoch 7, Training loss 84716.9140625, Validation loss 84716.9140625
2021-11-18 16:14:31,203:INFO:Epoch 8, Training loss 84716.9140625, Validation loss 84716.9140625
2021-11-18 16:14:34,852:INFO:Epoch 9, Training loss 84716.9140625, Validation loss 84716.9140625
2021-11-18 16:14:38,491:INFO:Epoch 10, Training loss 84716.9140625, Validation loss 84716.9140625
2021-11-18 16:14:42,280:INFO:Epoch 11, Training loss 84716.9140625, Validation loss 84716.9140625
2021-11-18 16:14:42,284:INFO:Detected stagant training, reset the weights
2021-11-18 16:14:46,010:INFO:Epoch 12, Training loss 84716.9140625, Validation loss 84716.9140625
2021-11-18 16:14:46,013:INFO:Detected stagant training, reset the weights
2021-11-18 16:14:49,767:INFO:Epoch 13, Training loss 84716.9140625, Validation loss 84716.9140625
2021-11-18 16:14:49,771:INFO:Detected stagant training, reset the weights
2021-11-18 16:14:53,345:INFO:Epoch 14, Training loss 81522.5625, Validation loss 80949.28125
2021-11-18 16:14:57,075:INFO:Epoch 15, Training loss 80951.7578125, Validation loss 80236.9765625
2021-11-18 16:15:00,835:INFO:Epoch 16, Training loss 80238.765625, Validation loss 79475.5390625
2021-11-18 16:15:04,429:INFO:Epoch 17, Training loss 79476.484375, Validation loss 78713.5703125
2021-11-18 16:15:08,132:INFO:Epoch 18, Training loss 78713.9609375, Validation loss 77983.390625
2021-11-18 16:15:11,931:INFO:Epoch 19, Training loss 77983.53125, Validation loss 77304.53125
2021-11-18 16:15:15,598:INFO:Epoch 20, Training loss 77304.5390625, Validation loss 76687.6328125
2021-11-18 16:15:19,236:INFO:Epoch 21, Training loss 76687.15625, Validation loss 76136.9609375
2021-11-18 16:15:22,923:INFO:Epoch 22, Training loss 76136.0703125, Validation loss 75653.90625
2021-11-18 16:15:26,724:INFO:Epoch 23, Training loss 75652.453125, Validation loss 75239.6484375
2021-11-18 16:15:30,442:INFO:Epoch 24, Training loss 75237.5859375, Validation loss 74890.21875
2021-11-18 16:15:34,064:INFO:Epoch 25, Training loss 74888.109375, Validation loss 74601.0546875
2021-11-18 16:15:37,840:INFO:Epoch 26, Training loss 74599.0390625, Validation loss 74369.109375
2021-11-18 16:15:41,561:INFO:Epoch 27, Training loss 74368.03125, Validation loss 74187.921875
2021-11-18 16:15:45,151:INFO:Epoch 28, Training loss 74187.59375, Validation loss 74050.6640625
2021-11-18 16:15:48,838:INFO:Epoch 29, Training loss 74051.515625, Validation loss 73952.015625
2021-11-18 16:15:52,537:INFO:Epoch 30, Training loss 73954.296875, Validation loss 73886.4296875
2021-11-18 16:15:56,239:INFO:Epoch 31, Training loss 73889.640625, Validation loss 73848.9296875
2021-11-18 16:15:59,919:INFO:Epoch 32, Training loss 73852.96875, Validation loss 73834.59375
2021-11-18 16:16:03,624:INFO:Epoch 33, Training loss 73839.21875, Validation loss 73837.703125
2021-11-18 16:16:07,401:INFO:Epoch 34, Training loss 73842.7578125, Validation loss 73851.1171875
2021-11-18 16:16:11,072:INFO:Epoch 35, Training loss 73856.28125, Validation loss 73869.28125
2021-11-18 16:16:14,684:INFO:Epoch 36, Training loss 73874.34375, Validation loss 73887.8828125
2021-11-18 16:16:18,483:INFO:Epoch 37, Training loss 73892.703125, Validation loss 73903.8125
2021-11-18 16:16:22,222:INFO:Epoch 38, Training loss 73908.40625, Validation loss 73915.3046875
2021-11-18 16:16:25,884:INFO:Epoch 39, Training loss 73919.7578125, Validation loss 73921.84375
2021-11-18 16:16:29,626:INFO:Epoch 40, Training loss 73926.09375, Validation loss 73923.8046875
2021-11-18 16:16:33,359:INFO:Epoch 41, Training loss 73927.953125, Validation loss 73921.7578125
2021-11-18 16:16:37,593:INFO:Epoch 42, Training loss 73925.78125, Validation loss 73916.3984375
2021-11-18 16:16:41,159:INFO:Epoch 43, Training loss 73920.2890625, Validation loss 73908.296875
2021-11-18 16:16:44,869:INFO:Epoch 44, Training loss 73912.1015625, Validation loss 73897.9765625
2021-11-18 16:16:48,638:INFO:Epoch 45, Training loss 73901.671875, Validation loss 73886.2734375
2021-11-18 16:16:52,286:INFO:Epoch 46, Training loss 73889.7578125, Validation loss 73873.703125
2021-11-18 16:16:55,951:INFO:Epoch 47, Training loss 73877.0703125, Validation loss 73860.8828125
2021-11-18 16:16:59,760:INFO:Epoch 48, Training loss 73864.0625, Validation loss 73848.3984375
2021-11-18 16:17:03,456:INFO:Epoch 49, Training loss 73851.234375, Validation loss 73836.6484375
2021-11-18 16:17:07,125:INFO:Epoch 50, Training loss 73839.0859375, Validation loss 73826.125
2021-11-18 16:17:10,730:INFO:Epoch 51, Training loss 73828.0546875, Validation loss 73817.2890625
2021-11-18 16:17:14,944:INFO:Epoch 52, Training loss 73818.8515625, Validation loss 73810.8515625
2021-11-18 16:17:18,717:INFO:Epoch 53, Training loss 73811.9921875, Validation loss 73806.953125
2021-11-18 16:17:22,332:INFO:Epoch 54, Training loss 73807.6875, Validation loss 73806.3359375
2021-11-18 16:17:26,088:INFO:Epoch 55, Training loss 73806.65625, Validation loss 73808.9765625
2021-11-18 16:17:29,883:INFO:Epoch 56, Training loss 73808.765625, Validation loss 73813.03125
2021-11-18 16:17:33,531:INFO:Epoch 57, Training loss 73812.4453125, Validation loss 73816.2734375
2021-11-18 16:17:37,168:INFO:Epoch 58, Training loss 73815.5078125, Validation loss 73817.6875
2021-11-18 16:17:40,859:INFO:Epoch 59, Training loss 73816.8671875, Validation loss 73817.375
2021-11-18 16:17:45,101:INFO:Epoch 60, Training loss 73816.546875, Validation loss 73815.890625
2021-11-18 16:17:48,784:INFO:Epoch 61, Training loss 73815.125, Validation loss 73813.9609375
2021-11-18 16:17:52,447:INFO:Epoch 62, Training loss 73813.3984375, Validation loss 73811.9609375
2021-11-18 16:17:56,234:INFO:Epoch 63, Training loss 73811.71875, Validation loss 73810.1875
2021-11-18 16:17:59,949:INFO:Epoch 64, Training loss 73810.171875, Validation loss 73808.8125
2021-11-18 16:18:03,586:INFO:Epoch 65, Training loss 73808.8671875, Validation loss 73807.8203125
2021-11-18 16:18:07,318:INFO:Epoch 66, Training loss 73807.8984375, Validation loss 73807.09375
2021-11-18 16:18:11,037:INFO:Epoch 67, Training loss 73807.203125, Validation loss 73806.5859375
2021-11-18 16:18:14,756:INFO:Epoch 68, Training loss 73806.75, Validation loss 73806.3359375
2021-11-18 16:18:18,453:INFO:Epoch 69, Training loss 73806.5234375, Validation loss 73806.2578125
2021-11-18 16:18:22,200:INFO:Epoch 70, Training loss 73806.4453125, Validation loss 73806.2890625
2021-11-18 16:18:25,953:INFO:Epoch 71, Training loss 73806.4765625, Validation loss 73806.3984375
2021-11-18 16:18:29,572:INFO:Epoch 72, Training loss 73806.546875, Validation loss 73806.5390625
2021-11-18 16:18:33,185:INFO:Epoch 73, Training loss 73806.6484375, Validation loss 73806.6875
2021-11-18 16:18:36,944:INFO:Epoch 74, Training loss 73806.765625, Validation loss 73806.828125
2021-11-18 16:18:40,659:INFO:Epoch 75, Training loss 73806.859375, Validation loss 73806.9296875
2021-11-18 16:18:44,338:INFO:Epoch 76, Training loss 73806.90625, Validation loss 73806.9921875
2021-11-18 16:18:48,034:INFO:Epoch 77, Training loss 73806.9140625, Validation loss 73807.0234375
2021-11-18 16:18:51,779:INFO:Epoch 78, Training loss 73806.8671875, Validation loss 73807.015625
2021-11-18 16:18:55,516:INFO:Epoch 79, Training loss 73806.765625, Validation loss 73806.9765625
2021-11-18 16:18:59,104:INFO:Epoch 80, Training loss 73806.6171875, Validation loss 73806.890625
2021-11-18 16:19:02,798:INFO:Epoch 81, Training loss 73806.4453125, Validation loss 73806.7734375
2021-11-18 16:19:06,598:INFO:Epoch 82, Training loss 73806.2421875, Validation loss 73806.6640625
2021-11-18 16:19:10,302:INFO:Epoch 83, Training loss 73806.0234375, Validation loss 73806.578125
2021-11-18 16:19:13,963:INFO:Epoch 84, Training loss 73805.765625, Validation loss 73806.5078125
2021-11-18 16:19:17,767:INFO:Epoch 85, Training loss 73805.484375, Validation loss 73806.46875
2021-11-18 16:19:21,512:INFO:Epoch 86, Training loss 73805.21875, Validation loss 73806.453125
2021-11-18 16:19:25,230:INFO:Epoch 87, Training loss 73805.03125, Validation loss 73806.484375
2021-11-18 16:19:28,900:INFO:Epoch 88, Training loss 73804.8984375, Validation loss 73806.5625
2021-11-18 16:19:32,668:INFO:Epoch 89, Training loss 73804.8203125, Validation loss 73806.6796875
2021-11-18 16:19:36,464:INFO:Epoch 90, Training loss 73804.7578125, Validation loss 73806.8125
2021-11-18 16:19:40,260:INFO:Epoch 91, Training loss 73804.7265625, Validation loss 73806.921875
2021-11-18 16:19:43,981:INFO:Epoch 92, Training loss 73804.671875, Validation loss 73807.03125
2021-11-18 16:19:47,679:INFO:Epoch 93, Training loss 73804.625, Validation loss 73807.1328125
2021-11-18 16:19:51,381:INFO:Epoch 94, Training loss 73804.5859375, Validation loss 73807.21875
2021-11-18 16:19:55,046:INFO:Epoch 95, Training loss 73804.53125, Validation loss 73807.2890625
2021-11-18 16:19:58,760:INFO:Epoch 96, Training loss 73804.4765625, Validation loss 73807.328125
2021-11-18 16:20:02,527:INFO:Epoch 97, Training loss 73804.40625, Validation loss 73807.3359375
2021-11-18 16:20:06,283:INFO:Epoch 98, Training loss 73804.3203125, Validation loss 73807.3125
2021-11-18 16:20:09,919:INFO:Epoch 99, Training loss 73804.2109375, Validation loss 73807.2734375
2021-11-18 16:20:13,761:INFO:Epoch 100, Training loss 73804.09375, Validation loss 73807.2109375
2021-11-18 16:20:17,465:INFO:Epoch 101, Training loss 73803.9765625, Validation loss 73807.15625
2021-11-18 16:20:21,158:INFO:Epoch 102, Training loss 73803.859375, Validation loss 73807.1015625
2021-11-18 16:20:24,898:INFO:Epoch 103, Training loss 73803.7578125, Validation loss 73807.0625
2021-11-18 16:20:28,635:INFO:Epoch 104, Training loss 73803.671875, Validation loss 73807.0390625
2021-11-18 16:20:32,387:INFO:Epoch 105, Training loss 73803.609375, Validation loss 73807.0234375
2021-11-18 16:20:36,118:INFO:Epoch 106, Training loss 73803.546875, Validation loss 73807.03125
2021-11-18 16:20:39,873:INFO:Epoch 107, Training loss 73803.484375, Validation loss 73807.0546875
2021-11-18 16:20:43,662:INFO:Epoch 108, Training loss 73803.4140625, Validation loss 73807.1015625
2021-11-18 16:20:47,337:INFO:Epoch 109, Training loss 73803.34375, Validation loss 73807.171875
2021-11-18 16:20:51,004:INFO:Epoch 110, Training loss 73803.28125, Validation loss 73807.2421875
2021-11-18 16:20:54,816:INFO:Epoch 111, Training loss 73803.234375, Validation loss 73807.3046875
2021-11-18 16:20:58,575:INFO:Epoch 112, Training loss 73803.1875, Validation loss 73807.3671875
2021-11-18 16:21:02,281:INFO:Epoch 113, Training loss 73803.1328125, Validation loss 73807.4375
2021-11-18 16:21:05,979:INFO:Epoch 114, Training loss 73803.078125, Validation loss 73807.5078125
2021-11-18 16:21:09,741:INFO:Epoch 115, Training loss 73803.03125, Validation loss 73807.5859375
2021-11-18 16:21:13,491:INFO:Epoch 116, Training loss 73802.984375, Validation loss 73807.65625
2021-11-18 16:21:17,125:INFO:Epoch 117, Training loss 73802.9375, Validation loss 73807.7421875
2021-11-18 16:21:20,951:INFO:Epoch 118, Training loss 73802.890625, Validation loss 73807.8203125
2021-11-18 16:21:24,776:INFO:Epoch 119, Training loss 73802.84375, Validation loss 73807.90625
2021-11-18 16:21:24,783:INFO:Finished training, producing training report at /data/theorie/jthoeve/ML4EFT_higgs/models/17_11/model_final_lin_cHq3_v7/mc_run_19/plots/training_report/
2021-11-18 16:21:25,713:WARNING:findfont: Font family ['sans-serif'] not found. Falling back to DejaVu Sans.
